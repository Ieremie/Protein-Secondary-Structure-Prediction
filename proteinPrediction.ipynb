{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade utils\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} theano\n",
    "\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} keras\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade keras\n",
    "\n",
    "\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} tensorflow-gpu\n",
    "\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'secondary_proteins_prediction/data/cullpdb+profile_6133_filtered.npy.gz'\n",
    "TEST_PATH = 'secondary_proteins_prediction/data/cb513+profile_split1.npy.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gz(path):  # load a .npy.gz file\n",
    "    if path.endswith(\".gz\"):\n",
    "        f = open(path, 'rb')\n",
    "        return np.load(f)\n",
    "    else:\n",
    "        return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN DATA #####\n",
    "\n",
    "def get_train(path=TRAIN_PATH):\n",
    "    if not os.path.isfile(path):\n",
    "        print(\"Train path is not downloaded ...\")\n",
    "        subprocess.call(\"./download_train.sh\", shell=True)\n",
    "    else:\n",
    "        print(\"Train path is downloaded ...\")\n",
    "    print(\"Loading train data ...\")\n",
    "    X_in = load_gz(path)\n",
    "    X = np.reshape(X_in, (5534, 700, 57))\n",
    "    del X_in\n",
    "    X = X[:, :, :]\n",
    "    labels = X[:, :, 22:30]\n",
    "    mask = X[:, :, 30] * -1 + 1\n",
    "\n",
    "    a = np.arange(0, 21)\n",
    "    b = np.arange(35, 56)\n",
    "    c = np.hstack((a, b))\n",
    "  #  X = X[:, :, c]\n",
    "    \n",
    "    # getting meta\n",
    "    num_seqs = np.size(X, 0)\n",
    "    seqlen = np.size(X, 1)\n",
    "    d = np.size(X, 2)\n",
    "    num_classes = 8\n",
    "\n",
    "    #### REMAKING LABELS ####\n",
    "    X = X.astype(theano.config.floatX)\n",
    "    mask = mask.astype(theano.config.floatX)\n",
    "    # Dummy -> concat\n",
    "    vals = np.arange(0, 8)\n",
    "    labels_new = np.zeros((num_seqs, seqlen))\n",
    "    for i in range(np.size(labels, axis=0)):\n",
    "        labels_new[i, :] = np.dot(labels[i, :, :], vals)\n",
    "    labels_new = labels_new.astype('int32')\n",
    "    labels = labels_new\n",
    "    print(labels.shape)\n",
    "\n",
    "    print(\"Loading splits ...\")\n",
    "    ##### SPLITS #####\n",
    "    # getting splits (cannot run before splits are made)\n",
    "    # split = np.load(\"data/split.pkl\")\n",
    "\n",
    "    seq_names = np.arange(0, num_seqs)\n",
    "    # np.random.shuffle(seq_names)\n",
    "\n",
    "    X_train = X[seq_names[0:5278]]\n",
    "    X_valid = X[seq_names[5278:5534]]\n",
    "    labels_train = labels[seq_names[0:5278]]\n",
    "    labels_valid = labels[seq_names[5278:5534]]\n",
    "    mask_train = mask[seq_names[0:5278]]\n",
    "    mask_valid = mask[seq_names[5278:5534]]\n",
    "    num_seq_train = np.size(X_train, 0)\n",
    "    num_seq_valid = np.size(X_valid, 0)\n",
    "    return X_train, X_valid, labels_train, labels_valid, mask_train, \\\n",
    "           mask_valid, num_seq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path is downloaded ...\n",
      "Loading train data ...\n",
      "(5534, 700)\n",
      "Loading splits ...\n",
      "Done loading train\n",
      "(5278, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = 'secondary_proteins_prediction/data/cullpdb+profile_6133_filtered.npy.gz'\n",
    "X_train, X_valid, labels_train, labels_valid, mask_train, mask_valid, _ = get_train(TRAIN_PATH)\n",
    "print(\"Done loading train\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(path=TEST_PATH):\n",
    "    if not os.path.isfile(path):\n",
    "        subprocess.call(\"./download_test.sh\", shell=True)\n",
    "    print(\"Loading test data ...\")\n",
    "    X_test_in = load_gz(path)\n",
    "    X_test = np.reshape(X_test_in, (514, 700, 57))\n",
    "    del X_test_in\n",
    "    X_test = X_test[:, :, :].astype(theano.config.floatX)\n",
    "    labels_test = X_test[:, :, 22:30].astype('int32')\n",
    "    mask_test = X_test[:, :, 30].astype(theano.config.floatX) * -1 + 1\n",
    "\n",
    "    a = np.arange(0, 21)\n",
    "    b = np.arange(35, 56)\n",
    "    c = np.hstack((a, b))\n",
    "   #X_test = X_test[:, :, c]\n",
    "\n",
    "    # getting meta\n",
    "    seqlen = np.size(X_test, 1)\n",
    "    d = np.size(X_test, 2)\n",
    "    num_classes = 8\n",
    "    num_seq_test = np.size(X_test, 0)\n",
    "    del a, b, c\n",
    "\n",
    "    ## DUMMY -> CONCAT ##\n",
    "    vals = np.arange(0, 8)\n",
    "    labels_new = np.zeros((num_seq_test, seqlen))\n",
    "    for i in range(np.size(labels_test, axis=0)):\n",
    "        labels_new[i, :] = np.dot(labels_test[i, :, :], vals)\n",
    "    labels_new = labels_new.astype('int32')\n",
    "    labels_test = labels_new\n",
    "\n",
    "    ### ADDING BATCH PADDING ###\n",
    "\n",
    "    X_add = np.zeros((126, seqlen, d))\n",
    "    label_add = np.zeros((126, seqlen))\n",
    "    mask_add = np.zeros((126, seqlen))\n",
    "\n",
    "    X_test = np.concatenate((X_test, X_add), axis=0).astype(theano.config.floatX)\n",
    "    labels_test = np.concatenate((labels_test, label_add), axis=0).astype('int32')\n",
    "    mask_test = np.concatenate((mask_test, mask_add), axis=0).astype(theano.config.floatX)\n",
    "    return X_test, mask_test, labels_test, num_seq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data ...\n",
      "Done loading test\n",
      "(640, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = 'secondary_proteins_prediction/data/cb513+profile_split1.npy.gz'\n",
    "X_test, mask_test, labels_test, num_seq_test = get_test(TEST_PATH)\n",
    "print(\"Done loading test\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Make 1 hot encoded class - from Q8 to Q3\n",
    "       #Reshape the dataset so it has 700*windowSize seq that map to a class\n",
    "       #Look inside lasagne to see how we disregard the padding\n",
    "##\n",
    "\n",
    "def q8ClassToQ3(q8Labels):\n",
    "    index = -1\n",
    "    q3 = np.zeros(3)\n",
    "    for i in range(np.size(q8Labels)):\n",
    "        if q8Labels[i] == 1:\n",
    "            index = i\n",
    "    #Helix\n",
    "    if index == 5 or index == 3 or index == 4 : # H ,G, I\n",
    "        q3[0] = 1   \n",
    "    #beta    \n",
    "    if index == 1 or index == 2: # B, E\n",
    "        q3[1] = 1    \n",
    "    #coil    \n",
    "    if index == 7 or index == 6 or index == 0 : # T, S, L\n",
    "        q3[2] = 1\n",
    "    return q3\n",
    "\n",
    "def q8ClassToQ2(q8Labels):\n",
    "    index = -1\n",
    "    q2 = np.zeros(2)\n",
    "    for i in range(np.size(q8Labels)):\n",
    "        if q8Labels[i] == 1:\n",
    "            index = i\n",
    "    #Helix\n",
    "    if index == 5 or index == 3 or index == 4 : # H ,G, I\n",
    "        q2[0] = 1\n",
    "    else:\n",
    "        q2[1] = 1  \n",
    "    return q2\n",
    "\n",
    "def changeQ8Class(dataSet, reductionFunction, numberOfFeatures):\n",
    "\n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    labels_new = np.zeros((num_seqs, seqlen, numberOfFeatures))\n",
    "\n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        for j in range(np.size(dataSet, axis=1)):\n",
    "            q3OneHot = reductionFunction(dataSet[i, j, 22:30])\n",
    "            features = np.concatenate((dataSet[i, j, 0:21], q3OneHot), axis=None)\n",
    "            features = np.concatenate((features, dataSet[i, j, 35:56]), axis=None)\n",
    "            labels_new[i][j] = features\n",
    "    return labels_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapClassLabel(features, classLabel, classSize):\n",
    "\n",
    "    res = np.concatenate((features[0:21], classLabel), axis=None)\n",
    "    res = np.concatenate((res, features[ (21+classSize) :]), axis=None)\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#num_classes should be q8, q3 or maybe q2?\n",
    "def proteinSequenceToWindowSequence(windowSize, predictionIndex , dataSet, classSize):\n",
    "   \n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    features = np.size(dataSet, 2)\n",
    "    dataSet_new = np.zeros((num_seqs, seqlen - windowSize + 1, windowSize, features))\n",
    "    \n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        for j in range(np.size(dataSet, axis=1) - windowSize + 1):\n",
    "            classLabel = dataSet[i][j + predictionIndex][21 : (21+classSize) ]\n",
    "            for k in range(windowSize):\n",
    "                dataSet_new[i][j][k] = swapClassLabel(dataSet[i][j+k], classLabel, classSize)\n",
    "            \n",
    "    return dataSet_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWindowsWithPadding(dataSet, windowSize, numberOfFeatures):\n",
    "    \n",
    "    dataSet = np.reshape(dataSet, (dataSet.shape[0]*dataSet.shape[1], windowSize, numberOfFeatures))\n",
    "    dataSet = dataSet[np.count_nonzero( dataSet, axis=(1,2))>(int(windowSize/2)*numberOfFeatures), :, :] \n",
    "    \n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 7\n",
    "predictionIndex = 3\n",
    "classSize = 2  # 2 or 3 \n",
    "numberOfFeatures = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 700, 57)\n",
      "(5278, 700, 44) changed train data to class of size  2\n",
      "(5278, 694, 7, 44) changed train data  to window sequence of size  7\n",
      "(1103472, 7, 44) filtered windows withouth padding of train data \n",
      "(256, 700, 57)\n",
      "(256, 700, 44) changed validation data to class size  2\n",
      "(256, 694, 7, 44) changed validation data to window sequence of size  7\n",
      "(52176, 7, 44) filtered windows withouth padding of validation data\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = changeQ8Class(X_train, q8ClassToQ2, numberOfFeatures)\n",
    "print(X_train.shape, \"changed train data to class of size \", classSize)\n",
    "X_train_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_train, classSize)\n",
    "print(X_train_window.shape, \"changed train data  to window sequence of size \", windowSize)\n",
    "X_train_window = removeWindowsWithPadding(X_train_window , windowSize, numberOfFeatures)\n",
    "print(X_train_window.shape, \"filtered windows withouth padding of train data \")\n",
    "\n",
    "print(X_valid.shape)\n",
    "X_valid = changeQ8Class(X_valid, q8ClassToQ2, numberOfFeatures)\n",
    "print(X_valid.shape, \"changed validation data to class size \", classSize)\n",
    "X_valid_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_valid, classSize)\n",
    "print(X_valid_window.shape, \"changed validation data to window sequence of size \", windowSize)\n",
    "X_valid_window = removeWindowsWithPadding(X_valid_window , windowSize, numberOfFeatures)\n",
    "print(X_valid_window.shape, \"filtered windows withouth padding of validation data\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 700\n",
    "amino_acid_residues = 21\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103472, 7, 21) training data\n",
      "(1103472, 7, 2) labels for training data\n",
      "(52176, 7, 21) validation data\n",
      "(52176, 7, 2) labels for training validation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_final = X_train_window[:,:,0:21]\n",
    "y_train_final = X_train_window[:,:,21 : (21+classSize)]\n",
    "print(x_train_final.shape, \"training data\")\n",
    "print(y_train_final.shape, \"labels for training data\")\n",
    "\n",
    "x_valid_final = X_valid_window[:,:,0:21]\n",
    "y_valid_final = X_valid_window[:,:,21 : (21+classSize)]\n",
    "print(x_valid_final.shape, \"validation data\")\n",
    "print(y_valid_final.shape, \"labels for training validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0128 19:31:42.219681 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0128 19:31:42.219681 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0128 19:31:42.220681 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0128 19:31:44.429045 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0128 19:31:49.362160 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0128 19:31:49.389091 12732 deprecation.py:506] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0128 19:31:49.460906 12732 deprecation_wrapper.py:119] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper Parameters\n",
      "\n",
      "Learning Rate: 0.0005\n",
      "Drop out: 0.3\n",
      "Batch dim: 64\n",
      "Number of epochs: 20\n",
      "\n",
      "Loss: categorical_crossentropy\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 7, 128)            29696     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 7, 64)             90176     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 7, 2)              1410      \n",
      "=================================================================\n",
      "Total params: 121,282\n",
      "Trainable params: 121,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv1D, AveragePooling1D, MaxPooling1D, TimeDistributed, LeakyReLU, BatchNormalization, Flatten\n",
    "from keras import optimizers, callbacks\n",
    "from keras.regularizers import l2\n",
    "\n",
    "LR = 0.0005\n",
    "drop_out = 0.3\n",
    "batch_dim = 64\n",
    "nn_epochs = 20\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "m = Sequential()\n",
    "m.add(Conv1D(128, 11, padding='same', activation='relu', input_shape=(windowSize, amino_acid_residues)))\n",
    "m.add(Dropout(drop_out))\n",
    "m.add(Conv1D(64, 11, padding='same', activation='relu'))\n",
    "m.add(Dropout(drop_out))\n",
    "m.add(Conv1D(num_classes, 11, padding='same', activation='softmax'))\n",
    "opt = optimizers.Adam(lr=LR)\n",
    "m.compile(optimizer=opt, loss=loss,metrics=['accuracy', 'mae'])\n",
    "\n",
    "print(\"\\nHyper Parameters\\n\")\n",
    "print(\"Learning Rate: \" + str(LR))\n",
    "print(\"Drop out: \" + str(drop_out))\n",
    "print(\"Batch dim: \" + str(batch_dim))\n",
    "print(\"Number of epochs: \" + str(nn_epochs))\n",
    "print(\"\\nLoss: \" + loss + \"\\n\")\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0128 19:32:19.397916 12732 deprecation.py:323] From C:\\Apps\\Anaconda3\\envs\\gpu-cuda10\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1103472 samples, validate on 52176 samples\n",
      "Epoch 1/20\n",
      "1103472/1103472 [==============================] - 65s 59us/step - loss: 0.5158 - acc: 0.7467 - mean_absolute_error: 0.3430 - val_loss: 0.5009 - val_acc: 0.7565 - val_mean_absolute_error: 0.3317\n",
      "Epoch 2/20\n",
      "1103472/1103472 [==============================] - 62s 56us/step - loss: 0.5044 - acc: 0.7538 - mean_absolute_error: 0.3341 - val_loss: 0.4997 - val_acc: 0.7579 - val_mean_absolute_error: 0.3362\n",
      "Epoch 3/20\n",
      "1103472/1103472 [==============================] - 62s 56us/step - loss: 0.5004 - acc: 0.7564 - mean_absolute_error: 0.3311 - val_loss: 0.4991 - val_acc: 0.7575 - val_mean_absolute_error: 0.3319\n",
      "Epoch 4/20\n",
      "1103472/1103472 [==============================] - 62s 56us/step - loss: 0.4974 - acc: 0.7582 - mean_absolute_error: 0.3289 - val_loss: 0.5015 - val_acc: 0.7568 - val_mean_absolute_error: 0.3380\n",
      "Epoch 5/20\n",
      "1103472/1103472 [==============================] - 61s 55us/step - loss: 0.4951 - acc: 0.7593 - mean_absolute_error: 0.3272 - val_loss: 0.5021 - val_acc: 0.7566 - val_mean_absolute_error: 0.3432\n",
      "Epoch 6/20\n",
      " 706176/1103472 [==================>...........] - ETA: 22s - loss: 0.4925 - acc: 0.7615 - mean_absolute_error: 0.3252"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time = timer()\n",
    "history = m.fit(x_train_final, y_train_final, epochs=nn_epochs, batch_size=batch_dim, validation_data=(x_valid_final, y_valid_final) ,shuffle=True)\n",
    "\n",
    "end_time = timer()\n",
    "print(\"\\n\\nTime elapsed: \" + \"{0:.2f}\".format((end_time - start_time)) + \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7e86dda5782c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Plot training & validation accuracy values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('accuracyRight.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('lossRight.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-424dbf6be590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"windowSize7RightHistory.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"windowSize7RightHistory.pickle\",\"wb\")\n",
    "pickle.dump(history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pkl_filename = \"windowSize7RightModel.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(m, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q8ClassLabelsToQ3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-936c27b209bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq8ClassLabelsToQ3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproteinSequenceToWindowSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictionIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremoveDuplicatesWindowDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_window\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'q8ClassLabelsToQ3' is not defined"
     ]
    }
   ],
   "source": [
    "X_test = q8ClassLabelsToQ3(X_test)\n",
    "X_test_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_test)\n",
    "X_test_window = removeDuplicatesWindowDataSet(X_test_window , windowSize)\n",
    "print(X_train_window.shape)\n",
    "\n",
    "x_test_final = X_test_window[:,:,0:21]\n",
    "y_test_final = X_test_window[:,:,21:24]\n",
    "print(x_test_final.shape)\n",
    "print(y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = m.evaluate(x_test_final, y_test_final)\n",
    "print(\"Loss: \" + str(scores[0]) + \", Accuracy: \" + str(scores[1]) + \", MAE: \" + str(scores[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
