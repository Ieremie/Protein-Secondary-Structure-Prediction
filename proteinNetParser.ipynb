{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Text-based parser for ProteinNet Records.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Mohammed AlQuraishi\"\n",
    "__copyright__ = \"Copyright 2019, Harvard Medical School\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "# imports\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "NUM_DIMENSIONS = 3\n",
    "\n",
    "# Functions for conversion from Mathematica protein files to TFRecords\n",
    "_aa_dict = {'A': '0', 'C': '1', 'D': '2', 'E': '3', 'F': '4', 'G': '5', 'H': '6', 'I': '7', 'K': '8', 'L': '9', 'M': '10', 'N': '11', 'P': '12', 'Q': '13', 'R': '14', 'S': '15', 'T': '16', 'V': '17', 'W': '18', 'Y': '19'}\n",
    "_dssp_dict = {'L': '0', 'H': '1', 'B': '2', 'E': '3', 'G': '4', 'I': '5', 'T': '6', 'S': '7'}\n",
    "_mask_dict = {'-': '0', '+': '1'}\n",
    "\n",
    "\n",
    "def letter_to_num(string, dict_):\n",
    "    \"\"\" Convert string of letters to list of ints \"\"\"\n",
    "    patt = re.compile('[' + ''.join(dict_.keys()) + ']')\n",
    "    num_string = patt.sub(lambda m: dict_[m.group(0)] + ' ', string)\n",
    "    num = [int(i) for i in num_string.split()]\n",
    "    return num\n",
    "\n",
    "def read_record(file_, num_evo_entries):\n",
    "    \"\"\" Read a Mathematica protein record from file and convert into dict. \"\"\"\n",
    "    \n",
    "    dict_ = {}\n",
    "    \n",
    "            \n",
    "    while True:\n",
    "        next_line = file_.readline()\n",
    "        if next_line == '[ID]' + '\\n':\n",
    "            id_ = file_.readline()[:-1]\n",
    "            dict_.update({'id': id_})\n",
    "        elif next_line == '[PRIMARY]' + '\\n':\n",
    "            primary = letter_to_num(file_.readline()[:-1], _aa_dict)\n",
    "            dict_.update({'primary': primary})\n",
    "        elif next_line == '[EVOLUTIONARY]' + '\\n':\n",
    "            evolutionary = []\n",
    "            for residue in range(num_evo_entries): evolutionary.append([float(step) for step in file_.readline().split()])\n",
    "            dict_.update({'evolutionary': evolutionary})\n",
    "        elif next_line == '[SECONDARY]' + '\\n':\n",
    "            print(next_line)\n",
    "            secondary = letter_to_num(file_.readline()[:-1], _dssp_dict)\n",
    "            dict_.update({'secondary': secondary})\n",
    "        elif next_line == '[TERTIARY]' + '\\n':\n",
    "            tertiary = []\n",
    "            for axis in range(NUM_DIMENSIONS): tertiary.append([float(coord) for coord in file_.readline().split()])\n",
    "            dict_.update({'tertiary': tertiary})\n",
    "        elif next_line == '[MASK]' + '\\n':\n",
    "            mask = letter_to_num(file_.readline()[:-1], _mask_dict)\n",
    "            dict_.update({'mask': mask})\n",
    "        elif next_line == '\\n':\n",
    "            return dict_\n",
    "        elif next_line == '':\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_protein_shape(dict_):\n",
    "    protein = []\n",
    "    amino_acid_f = []\n",
    "    for i in range(len(dict_['primary'])):\n",
    "        #primary structure\n",
    "        prim_lab = [0] * 21\n",
    "        index = dict_['primary'][i]\n",
    "        prim_lab[index] = 1\n",
    "    \n",
    "        #secondary label\n",
    "        sec_lab = [0] * 8\n",
    "    \n",
    "        #PSSM\n",
    "        pssm = []\n",
    "        for j in range(21):\n",
    "            pssm.append(dict_['evolutionary'][j][i])\n",
    "        \n",
    "        amino_acid_f = prim_lab + sec_lab + pssm    \n",
    "        protein.append(amino_acid_f)\n",
    "        amino_acid_f = []\n",
    "\n",
    "    while (len (protein) < 700):\n",
    "        no_seq = [0] * 50\n",
    "        protein.append(no_seq)\n",
    "    \n",
    "    #returns protein in shape (1,700,50)\n",
    "    protein = np.array(protein)   \n",
    "    return protein    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "def save_parti_dataset(proteins, caspName , index):\n",
    "    \n",
    "    dataset = np.zeros(( len(proteins), 700, 50))\n",
    "\n",
    "    for i in range ( len(proteins) ):\n",
    "        dataset[i] = proteins[i]\n",
    "    \n",
    "    f = gzip.GzipFile( caspName + \"-\" + str(index) + '.npy.gz', \"w\")\n",
    "    np.save(f, dataset)\n",
    "    f.close()\n",
    "    print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "saving dataset\n",
      "(5278, 700, 50)\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "saving dataset\n",
      "(5278, 700, 50)\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "14000\n",
      "15000\n",
      "saving dataset\n",
      "(5278, 700, 50)\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "saving dataset\n",
      "(5278, 700, 50)\n",
      "22000\n",
      "23000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "# main. accepts two command-line arguments: input file and the number of entries in evo profiles, and outputs dicts to stdout\n",
    "\n",
    "input_path =   \"casp12/training_30\"  #= sys.argv[1] \n",
    "num_evo_entries = 21 #int(sys.argv[2]) if len(sys.argv) == 3 else 20 # default number of evo entries\n",
    "\n",
    "input_file = open(input_path, 'r')\n",
    "   \n",
    "proteins = [] #np.zeros((1,700,50)) \n",
    "\n",
    "i = 0\n",
    "datIndex = 0\n",
    "transkaya_conter = 0\n",
    "while True:\n",
    "    \n",
    "    #progress bar\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    #save first partition of dataset - same size as transkaya        \n",
    "    if transkaya_conter == 5278:\n",
    "        print(\"saving dataset\")\n",
    "        save_parti_dataset(proteins, input_path, datIndex)\n",
    "        proteins = []\n",
    "        transkaya_conter = 0\n",
    "        datIndex += 1\n",
    "    \n",
    "    #reading file\n",
    "    dict_ = read_record(input_file, num_evo_entries)\n",
    "    if dict_ is not None:\n",
    "        protein = dict_to_protein_shape(dict_)\n",
    "        \n",
    "        #700 is max len for proteins\n",
    "        if (protein.shape[0] == 700):\n",
    "            proteins.append(protein)\n",
    "            transkaya_conter += 1\n",
    "            i += 1 \n",
    "            #proteins = np.vstack((proteins,protein))\n",
    "    else:\n",
    "        input_file.close()\n",
    "        break\n",
    "    \n",
    "\n",
    "#removing the first elemnt used for stacking    \n",
    "#proteins = np.delete(proteins, 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "\n",
    "#secondary label is not present in the files\n",
    "with open('casp12/training_100', 'rb', 0) as file, \\\n",
    "     mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as s:\n",
    "    if s.find(b'SECONDARY') != -1:\n",
    "        print('true')\n",
    "    else: \n",
    "        print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1036506  shape of dataset\n",
      "all togheter  1036506\n",
      "1\n",
      "1044591  shape of dataset\n",
      "all togheter  2081097\n",
      "2\n",
      "1035235  shape of dataset\n",
      "all togheter  3116332\n",
      "3\n",
      "1036940  shape of dataset\n",
      "all togheter  4153272\n",
      "4\n",
      "1039488  shape of dataset\n",
      "all togheter  5192760\n",
      "5\n",
      "1041722  shape of dataset\n",
      "all togheter  6234482\n",
      "6\n",
      "1039770  shape of dataset\n",
      "all togheter  7274252\n",
      "7\n",
      "1036662  shape of dataset\n",
      "all togheter  8310914\n",
      "8\n",
      "1028068  shape of dataset\n",
      "all togheter  9338982\n",
      "9\n",
      "1030480  shape of dataset\n",
      "all togheter  10369462\n",
      "10\n",
      "1021110  shape of dataset\n",
      "all togheter  11390572\n",
      "11\n",
      "1034139  shape of dataset\n",
      "all togheter  12424711\n",
      "12\n",
      "1014951  shape of dataset\n",
      "all togheter  13439662\n",
      "13\n",
      "1024966  shape of dataset\n",
      "all togheter  14464628\n",
      "14\n",
      "1031661  shape of dataset\n",
      "all togheter  15496289\n",
      "15\n",
      "1017105  shape of dataset\n",
      "all togheter  16513394\n",
      "16\n",
      "1031984  shape of dataset\n",
      "all togheter  17545378\n",
      "17\n",
      "1030908  shape of dataset\n",
      "all togheter  18576286\n",
      "18\n",
      "1032898  shape of dataset\n",
      "all togheter  19609184\n"
     ]
    }
   ],
   "source": [
    "#finding the number of total proteins before creating numpy on disk\n",
    "nr_windows = 0\n",
    "for i in range(19):\n",
    "    print(i)\n",
    "    f = gzip.GzipFile( 'casp12/training_100-' + str(i) + 'window19Middle' +'.npy.gz', \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape[0], \" shape of dataset\")\n",
    "    nr_windows += dataset_part.shape[0]\n",
    "    print(\"all togheter \", nr_windows)\n",
    "    \n",
    "    del dataset_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mfid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'\\0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[0mfid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d5ebc07b01d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 19609184\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#all 19 partitions in 1 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19609184\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;31m# same as memmap copies (e.g. memmap + 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "filename = \"casp12/proteinNet-all-windows-19-middle\"\n",
    "# 19609184\n",
    "#all 19 partitions in 1 dataset\n",
    "fp = np.memmap(filename, dtype='float64', mode='w+', shape=(19609184, 19, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding all the information to big dataset\n",
    "l = 0\n",
    "r = 0\n",
    "for i in range(19):\n",
    "    \n",
    "    f = gzip.GzipFile( 'casp12/training_100-' + str(i) + 'window19Middle' +'.npy.gz', \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape)\n",
    "    \n",
    "    r += dataset_part.shape[0]\n",
    "    print(l, \" \", r)\n",
    "    fp[l:r] =  dataset_part\n",
    "    l = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fp.flush()\n",
    "del fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = np.memmap(filename, dtype='float64', mode='r', shape=(1133502 * 2, 19, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0\n",
    "1000\n",
    "2000\n",
    "3000\n",
    "4000\n",
    "5000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "6000\n",
    "7000\n",
    "8000\n",
    "9000\n",
    "10000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "11000\n",
    "12000\n",
    "13000\n",
    "14000\n",
    "15000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "16000\n",
    "17000\n",
    "18000\n",
    "19000\n",
    "20000\n",
    "21000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "22000\n",
    "23000\n",
    "24000\n",
    "25000\n",
    "26000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "27000\n",
    "28000\n",
    "29000\n",
    "30000\n",
    "31000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "32000\n",
    "33000\n",
    "34000\n",
    "35000\n",
    "36000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "37000\n",
    "38000\n",
    "39000\n",
    "40000\n",
    "41000\n",
    "41000\n",
    "42000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "43000\n",
    "44000\n",
    "45000\n",
    "46000\n",
    "47000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "48000\n",
    "49000\n",
    "50000\n",
    "51000\n",
    "52000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "53000\n",
    "54000\n",
    "55000\n",
    "56000\n",
    "57000\n",
    "58000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "59000\n",
    "60000\n",
    "61000\n",
    "62000\n",
    "63000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "64000\n",
    "65000\n",
    "66000\n",
    "67000\n",
    "68000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "69000\n",
    "70000\n",
    "71000\n",
    "72000\n",
    "73000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "74000\n",
    "75000\n",
    "76000\n",
    "77000\n",
    "78000\n",
    "79000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "80000\n",
    "81000\n",
    "82000\n",
    "83000\n",
    "84000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "85000\n",
    "86000\n",
    "87000\n",
    "88000\n",
    "89000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "90000\n",
    "91000\n",
    "92000\n",
    "93000\n",
    "94000\n",
    "95000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "96000\n",
    "96000\n",
    "97000\n",
    "98000\n",
    "99000\n",
    "100000\n",
    "saving dataset\n",
    "(5278, 700, 50)\n",
    "101000\n",
    "102000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
