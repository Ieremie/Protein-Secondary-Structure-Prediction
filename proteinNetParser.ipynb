{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Text-based parser for ProteinNet Records.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Mohammed AlQuraishi\"\n",
    "__copyright__ = \"Copyright 2019, Harvard Medical School\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "# imports\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "NUM_DIMENSIONS = 3\n",
    "\n",
    "# Functions for conversion from Mathematica protein files to TFRecords\n",
    "_aa_dict = {'A': '0', 'C': '1', 'D': '2', 'E': '3', 'F': '4', 'G': '5', 'H': '6', 'I': '7', 'K': '8', 'L': '9', 'M': '10', 'N': '11', 'P': '12', 'Q': '13', 'R': '14', 'S': '15', 'T': '16', 'V': '17', 'W': '18', 'Y': '19'}\n",
    "_dssp_dict = {'L': '0', 'H': '1', 'B': '2', 'E': '3', 'G': '4', 'I': '5', 'T': '6', 'S': '7'}\n",
    "_mask_dict = {'-': '0', '+': '1'}\n",
    "\n",
    "\n",
    "def letter_to_num(string, dict_):\n",
    "    \"\"\" Convert string of letters to list of ints \"\"\"\n",
    "    patt = re.compile('[' + ''.join(dict_.keys()) + ']')\n",
    "    num_string = patt.sub(lambda m: dict_[m.group(0)] + ' ', string)\n",
    "    num = [int(i) for i in num_string.split()]\n",
    "    return num\n",
    "\n",
    "def read_record(file_, num_evo_entries):\n",
    "    \"\"\" Read a Mathematica protein record from file and convert into dict. \"\"\"\n",
    "    \n",
    "    dict_ = {}\n",
    "    \n",
    "            \n",
    "    while True:\n",
    "        next_line = file_.readline()\n",
    "        if next_line == '[ID]' + '\\n':\n",
    "            id_ = file_.readline()[:-1]\n",
    "            dict_.update({'id': id_})\n",
    "        elif next_line == '[PRIMARY]' + '\\n':\n",
    "            primary = letter_to_num(file_.readline()[:-1], _aa_dict)\n",
    "            dict_.update({'primary': primary})\n",
    "        elif next_line == '[EVOLUTIONARY]' + '\\n':\n",
    "            evolutionary = []\n",
    "            for residue in range(num_evo_entries): evolutionary.append([float(step) for step in file_.readline().split()])\n",
    "            dict_.update({'evolutionary': evolutionary})\n",
    "        elif next_line == '[SECONDARY]' + '\\n':\n",
    "            print(next_line)\n",
    "            secondary = letter_to_num(file_.readline()[:-1], _dssp_dict)\n",
    "            dict_.update({'secondary': secondary})\n",
    "        elif next_line == '[TERTIARY]' + '\\n':\n",
    "            tertiary = []\n",
    "            for axis in range(NUM_DIMENSIONS): tertiary.append([float(coord) for coord in file_.readline().split()])\n",
    "            dict_.update({'tertiary': tertiary})\n",
    "        elif next_line == '[MASK]' + '\\n':\n",
    "            mask = letter_to_num(file_.readline()[:-1], _mask_dict)\n",
    "            dict_.update({'mask': mask})\n",
    "        elif next_line == '\\n':\n",
    "            return dict_\n",
    "        elif next_line == '':\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_protein_shape(dict_):\n",
    "    protein = []\n",
    "    amino_acid_f = []\n",
    "    for i in range(len(dict_['primary'])):\n",
    "        #primary structure\n",
    "        prim_lab = [0] * 21\n",
    "        index = dict_['primary'][i]\n",
    "        prim_lab[index] = 1\n",
    "    \n",
    "        #secondary label\n",
    "        sec_lab = [0] * 8\n",
    "    \n",
    "        #PSSM\n",
    "        pssm = []\n",
    "        for j in range(21):\n",
    "            pssm.append(dict_['evolutionary'][j][i])\n",
    "        \n",
    "        amino_acid_f = prim_lab + sec_lab + pssm    \n",
    "        protein.append(amino_acid_f)\n",
    "        amino_acid_f = []\n",
    "\n",
    "    while (len (protein) < 700):\n",
    "        no_seq = [0] * 50\n",
    "        protein.append(no_seq)\n",
    "    \n",
    "    #returns protein in shape (1,700,50)\n",
    "    protein = np.array(protein)   \n",
    "    return protein    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "def save_parti_dataset(proteins, caspName , index):\n",
    "    \n",
    "    dataset = np.zeros(( len(proteins), 700, 50))\n",
    "\n",
    "    for i in range ( len(proteins) ):\n",
    "        dataset[i] = proteins[i]\n",
    "    \n",
    "    f = gzip.GzipFile( caspName + \"-\" + str(index) + '.npy.gz', \"w\")\n",
    "    np.save(f, dataset)\n",
    "    f.close()\n",
    "    print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main. accepts two command-line arguments: input file and the number of entries in evo profiles, and outputs dicts to stdout\n",
    "\n",
    "input_path =   \"casp12/training_30\"  #= sys.argv[1] \n",
    "num_evo_entries = 21 #int(sys.argv[2]) if len(sys.argv) == 3 else 20 # default number of evo entries\n",
    "\n",
    "input_file = open(input_path, 'r')\n",
    "   \n",
    "proteins = [] #np.zeros((1,700,50)) \n",
    "\n",
    "i = 0\n",
    "datIndex = 0\n",
    "transkaya_conter = 0\n",
    "while True:\n",
    "    \n",
    "    #progress bar\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    #save first partition of dataset - same size as transkaya        \n",
    "    if transkaya_conter == 5278:\n",
    "        print(\"saving dataset\")\n",
    "        save_parti_dataset(proteins, input_path, datIndex)\n",
    "        proteins = []\n",
    "        transkaya_conter = 0\n",
    "        datIndex += 1\n",
    "    \n",
    "    #reading file\n",
    "    dict_ = read_record(input_file, num_evo_entries)\n",
    "    if dict_ is not None:\n",
    "        protein = dict_to_protein_shape(dict_)\n",
    "        \n",
    "        #700 is max len for proteins\n",
    "        if (protein.shape[0] == 700):\n",
    "            proteins.append(protein)\n",
    "            transkaya_conter += 1\n",
    "            i += 1 \n",
    "            #proteins = np.vstack((proteins,protein))\n",
    "    else:\n",
    "        input_file.close()\n",
    "        break\n",
    "    \n",
    "\n",
    "#removing the first elemnt used for stacking    \n",
    "#proteins = np.delete(proteins, 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "\n",
    "#secondary label is not present in the files\n",
    "with open('casp12/training_100', 'rb', 0) as file, \\\n",
    "     mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as s:\n",
    "    if s.find(b'SECONDARY') != -1:\n",
    "        print('true')\n",
    "    else: \n",
    "        print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the number of total proteins before creating numpy on disk\n",
    "nr_windows = 0\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    f = gzip.GzipFile( 'casp12/training_30-' + str(i) + 'window19Middle' +'.npy.gz', \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape[0], \" shape of dataset\")\n",
    "    nr_windows += dataset_part.shape[0]\n",
    "    print(\"all togheter \", nr_windows)\n",
    "    \n",
    "    del dataset_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"casp12/proteinNet-all-windows-19-middle-30-thining\"\n",
    "# 19609184\n",
    "#all 19 partitions in 1 dataset\n",
    "fp = np.memmap(filename, dtype='float64', mode='w+', shape=(3763142, 19, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding all the information to big dataset\n",
    "l = 0\n",
    "r = 0\n",
    "for i in range(4):\n",
    "    \n",
    "    f = gzip.GzipFile( 'casp12/training_30-' + str(i) + 'window19Middle' +'.npy.gz', \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape)\n",
    "    \n",
    "    r += dataset_part.shape[0]\n",
    "    print(l, \" \", r)\n",
    "    fp[l:r] =  dataset_part\n",
    "    l = r\n",
    "    del dataset_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.flush()\n",
    "del fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = np.memmap(filename, dtype='float64', mode='r', shape=(3763142, 19, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gzip.GzipFile( 'casp12/proteinNet-all-windows-19-middle-30-thining' +'.npy.gz', \"w\")\n",
    "np.save(g, fp)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "f = gzip.GzipFile( 'casp12/proteinNet-all-windows-19-middle-30-thining' +'.npy.gz', \"r\")\n",
    "dataset_part =  np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
