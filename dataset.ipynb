{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import theano\n",
    "import gzip\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'secondary_proteins_prediction/data/cullpdb+profile_6133_filtered.npy.gz'\n",
    "TEST_PATH =  'secondary_proteins_prediction/data/cb513+profile_split1.npy.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gz(path):  # load a .npy.gz file\n",
    "    if path.endswith(\".gz\"):\n",
    "        f = open(path, 'rb')\n",
    "        return np.load(f)\n",
    "    else:\n",
    "        return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(path=TRAIN_PATH):\n",
    "    \n",
    "    X_in = load_gz(path)\n",
    "    print(X_in.shape)\n",
    "    X = np.reshape(X_in, (5534, 700, 57))\n",
    "    del X_in\n",
    "    X = X[:, :, :].astype(theano.config.floatX)\n",
    "  \n",
    "    seq_names = np.arange(0, np.size(X, 0))\n",
    "\n",
    "    X_train = X[seq_names[0:5278]]\n",
    "    #X_train = X[seq_names[0:5534]] #this is used for utilising the entire dataset as train\n",
    "    X_valid = X[seq_names[5278:5534]]\n",
    "    \n",
    "    return X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5534, 39900)\n",
      "Done loading train\n",
      "(5278, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid= get_train(TRAIN_PATH)\n",
    "print(\"Done loading train\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(path=TEST_PATH):\n",
    "    \n",
    "    X_test_in = load_gz(path)\n",
    "    X_test = np.reshape(X_test_in, (514, 700, 57))\n",
    "    del X_test_in\n",
    "    X_test = X_test[:, :, :].astype(theano.config.floatX)\n",
    "\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading test\n",
      "(514, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_test(TEST_PATH)\n",
    "print(\"Done loading test\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Make 1 hot encoded class - from Q8 to Q3\n",
    "       #Reshape the dataset so it has 700*windowSize seq that map to a class\n",
    "       #Look inside lasagne to see how we disregard the padding\n",
    "##\n",
    "\n",
    "def q8ClassToQ3(q8Labels):\n",
    "    \n",
    "    q3 = np.zeros(3)\n",
    "    index = np.argmax(q8Labels)\n",
    "    \n",
    "    #Helix\n",
    "    if index == 5 or index == 3 or index == 4 : # H ,G, I\n",
    "        q3[0] = 1   \n",
    "    #beta    \n",
    "    if index == 1 or index == 2: # B, E\n",
    "        q3[1] = 1    \n",
    "    #coil    \n",
    "    if index == 7 or index == 6 or index == 0 : # T, S, L\n",
    "        q3[2] = 1\n",
    "    return q3\n",
    "\n",
    "def q8ClassToQ2(q8Labels):\n",
    "    \n",
    "    q2 = np.zeros(2)\n",
    "    index = np.argmax(q8Labels)\n",
    "    #Helix\n",
    "    if index == 5: # or index == 3 or index == 4 : # H ,G, I\n",
    "        q2[0] = 1\n",
    "    else:\n",
    "        q2[1] = 1  \n",
    "    return q2\n",
    "\n",
    "def q8toQ8(q8Labels):\n",
    "    return q8Labels\n",
    "\n",
    "def changeQ8Class(dataSet, reductionFunction, numberOfFeatures):\n",
    "\n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    labels_new = np.zeros((num_seqs, seqlen, numberOfFeatures))\n",
    "\n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        for j in range(np.size(dataSet, axis=1)):\n",
    "            oneHot = reductionFunction(dataSet[i, j, 22:30])\n",
    "            features = np.concatenate((dataSet[i, j, 0:21], oneHot), axis=None)\n",
    "            features = np.concatenate((features, dataSet[i, j, 35:56]), axis=None)\n",
    "            labels_new[i][j] = features\n",
    "    return labels_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapClassLabel(features, classLabel, classSize):\n",
    "\n",
    "    res = np.concatenate((features[0:21], classLabel), axis=None)\n",
    "    res = np.concatenate((res, features[ (21+classSize) :]), axis=None)\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#num_classes should be q8, q3 or maybe q2?\n",
    "def proteinSequenceToWindowSequence(windowSize, predictionIndex , dataSet, classSize):\n",
    "   \n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    features = np.size(dataSet, 2)\n",
    "    dataSet_new = np.zeros((num_seqs, seqlen - windowSize + 1, windowSize, features))\n",
    "    \n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        for j in range(np.size(dataSet, axis=1) - windowSize):\n",
    "            classLabel = dataSet[i][j + predictionIndex][21 : (21+classSize) ]\n",
    "            for k in range(windowSize):\n",
    "                if predictionIndex != 0:\n",
    "                    dataSet_new[i][j][k] = swapClassLabel(dataSet[i][j+k], classLabel, classSize)\n",
    "                else:\n",
    "                    dataSet_new[i][j][k] = swapClassLabel(dataSet[i][j+k+1], classLabel, classSize)\n",
    "            \n",
    "    return dataSet_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWindowsWithPadding(dataSet, windowSize, numberOfFeatures):\n",
    "    \n",
    "    dataSet = np.reshape(dataSet, (dataSet.shape[0]*dataSet.shape[1], windowSize, numberOfFeatures))\n",
    "    dataSet = dataSet[np.count_nonzero( dataSet, axis=(1,2))>(int(windowSize/2)*23), :, :] \n",
    "    \n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_dataset(X_train, X_valid, reductionFunction, numberOfFeatures, classSize, predictionIndex, windowSize):\n",
    "    #print(X_train.shape)\n",
    "    #X_train = changeQ8Class(X_train, reductionFunction, numberOfFeatures)\n",
    "    print(X_train.shape, \"changed train data to class of size \", classSize)\n",
    "    X_train_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_train, classSize)\n",
    "    print(X_train_window.shape, \"changed train data  to window sequence of size \", windowSize)\n",
    "    X_train_window = removeWindowsWithPadding(X_train_window , windowSize, numberOfFeatures)\n",
    "    print(X_train_window.shape, \"filtered windows withouth padding of train data \")\n",
    "\n",
    "    #print(X_valid.shape)\n",
    "    X_valid_window = 0\n",
    "    #X_valid = changeQ8Class(X_valid, reductionFunction, numberOfFeatures)\n",
    "    #print(X_valid.shape, \"changed validation data to class size \", classSize)\n",
    "    #X_valid_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_valid, classSize)\n",
    "    #print(X_valid_window.shape, \"changed validation data to window sequence of size \", windowSize)\n",
    "    #X_valid_window = removeWindowsWithPadding(X_valid_window , windowSize, numberOfFeatures)\n",
    "    #print(X_valid_window.shape, \"filtered windows withouth padding of validation data\")\n",
    "    \n",
    "    return X_train_window, X_valid_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_tapped(oneHot, index, windowSize):\n",
    "\n",
    "    oneHot = oneHot.copy()\n",
    "    newOne = 0.5/(windowSize - 1) * index + 0.5\n",
    "    newZero = (1 - newOne) / (np.size(oneHot) - 1)\n",
    "        \n",
    "    oneHot = oneHot.astype(theano.config.floatX)\n",
    "    oneHot[ oneHot == 1] = newOne\n",
    "    oneHot[ oneHot == 0] = newZero\n",
    "\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tapped_one_dataset(dataSet, windowSize, classSize):\n",
    "    \n",
    "    newDataSet = dataSet.copy()\n",
    "    for i in range(np.size(newDataSet, axis=1)): \n",
    "        for j in range(np.size(newDataSet, axis=1)):\n",
    "\n",
    "            oneHot = one_hot_to_tapped( newDataSet[i, j, 0:21], j, windowSize)\n",
    "            features = np.concatenate((oneHot, newDataSet[i, j, 21:]), axis=None)\n",
    "            newDataSet[i][j] = features\n",
    "    \n",
    "    return newDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(X_train, X_valid, classSize, pssm = False):\n",
    "\n",
    "    if not pssm:\n",
    "        return (X_train[:,:,0:21], X_train[:,:,21 : (21+classSize)], \n",
    "                X_valid[:,:,0:21], X_valid[:,:,21 : (21+classSize)])\n",
    "    else:\n",
    "        return (X_train[:,:,21+classSize:], X_train[:,:,21 : (21+classSize)],\n",
    "                X_valid[:,:,21+classSize:], X_valid[:,:,21 : (21+classSize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 19 #19\n",
    "predictionIndex = 9\n",
    "classSize = 8  # 2 or 3 \n",
    "numberOfFeatures = 50 #50 #44 #45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    print(\"reading casp part dataset\")\n",
    "    f = gzip.GzipFile( 'casp12/training_30-' + str(i) + '.npy.gz',  \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape)\n",
    "    \n",
    "    X_train_window, X_valid_window = get_reshaped_dataset(dataset_part, 0, q8toQ8, numberOfFeatures, classSize, predictionIndex, windowSize)\n",
    "    print(X_train_window.shape)\n",
    "    \n",
    "    del dataset_part\n",
    "    print(\"saving casp part window dataset\")\n",
    "    g = gzip.GzipFile( 'casp12/training_30-' + str(i) + 'window19Middle' +'.npy.gz', \"w\")\n",
    "    np.save(g, X_train_window)\n",
    "    g.close()\n",
    "    del X_train_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_window, X_valid_window = get_reshaped_dataset(X_train, X_valid, q8toQ8, numberOfFeatures, classSize, predictionIndex, windowSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_dataset_window19Middle.npy', X_train_window) # save\n",
    "np.save('X_valid_window19Middle.npy', X_valid_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.GzipFile('all_dataset_window9LeftSideQ2.npy.gz', \"w\")\n",
    "np.save(f, X_train_window)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gzip.GzipFile('X_valid_window19Middle.npy.gz', \"w\")\n",
    "np.save(g, X_valid_window)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = changeQ8Class(X_test, q8ClassToQ2, numberOfFeatures)\n",
    "X_test_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_test, classSize)\n",
    "X_test_window = removeWindowsWithPadding(X_test_window , windowSize, numberOfFeatures)\n",
    "print(X_test_window.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.GzipFile('cb513_window19Q2.npy.gz', \"w\")\n",
    "np.save(f, X_test_window)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein nr  5277\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "#X_train = \n",
    "allValidWindows = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    \n",
    "    print(\"protein nr \" ,i)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    #creating padding version so we do not loose information\n",
    "    padded = np.zeros((700+18, 57))\n",
    "    padded[9:709] = X_train[i]\n",
    "    \n",
    "    for k in range(9):\n",
    "        padded[k] = X_train[i,0]\n",
    "    for k in range(709,718):\n",
    "        padded[k] = X_train[i,699]\n",
    "    \n",
    "    for k in range(718 - 19 + 1):\n",
    "        #no seq reached\n",
    "        if X_train[i,k,0:21].sum() == 0:\n",
    "            break\n",
    "            \n",
    "        window =  padded[k:k+19]\n",
    "        #setting the same label\n",
    "        window[:,22:30] = X_train[i,k, 22:30]\n",
    "        allValidWindows.append(window)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "allValidWindows = np.array(allValidWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1129862, 19, 57)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allValidWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.GzipFile('X_train_window19Middle-padding-repeating-last.npy.gz', \"w\")\n",
    "np.save(f, allValidWindows)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
