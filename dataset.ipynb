{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import theano\n",
    "import gzip\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'secondary_proteins_prediction/data/cullpdb+profile_6133_filtered.npy.gz'\n",
    "TEST_PATH =  'secondary_proteins_prediction/data/cb513+profile_split1.npy.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gz(path):  # load a .npy.gz file\n",
    "    if path.endswith(\".gz\"):\n",
    "        f = open(path, 'rb')\n",
    "        return np.load(f)\n",
    "    else:\n",
    "        return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(path=TRAIN_PATH):\n",
    "    \n",
    "    X_in = load_gz(path)\n",
    "    print(X_in.shape)\n",
    "    X = np.reshape(X_in, (5534, 700, 57))\n",
    "    del X_in\n",
    "    X = X[:, :, :].astype(theano.config.floatX)\n",
    "  \n",
    "    seq_names = np.arange(0, np.size(X, 0))\n",
    "\n",
    "    X_train = X[seq_names[0:5278]]\n",
    "    #X_train = X[seq_names[0:5534]] #this is used for utilising the entire dataset as train\n",
    "    X_valid = X[seq_names[5278:5534]]\n",
    "    \n",
    "    return X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5534, 39900)\n",
      "Done loading train\n",
      "(5278, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid= get_train(TRAIN_PATH)\n",
    "print(\"Done loading train\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(path=TEST_PATH):\n",
    "    \n",
    "    X_test_in = load_gz(path)\n",
    "    X_test = np.reshape(X_test_in, (514, 700, 57))\n",
    "    del X_test_in\n",
    "    X_test = X_test[:, :, :].astype(theano.config.floatX)\n",
    "\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading test\n",
      "(514, 700, 57)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_test(TEST_PATH)\n",
    "print(\"Done loading test\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Make 1 hot encoded class - from Q8 to Q3\n",
    "       #Reshape the dataset so it has 700*windowSize seq that map to a class\n",
    "       #Look inside lasagne to see how we disregard the padding\n",
    "##\n",
    "\n",
    "def q8ClassToQ3(q8Labels):\n",
    "    \n",
    "    q3 = np.zeros(3)\n",
    "    index = np.argmax(q8Labels)\n",
    "    \n",
    "    #Helix\n",
    "    if index == 5 or index == 3 or index == 4 : # H ,G, I\n",
    "        q3[0] = 1   \n",
    "    #beta    \n",
    "    if index == 1 or index == 2: # B, E\n",
    "        q3[1] = 1    \n",
    "    #coil    \n",
    "    if index == 7 or index == 6 or index == 0 : # T, S, L\n",
    "        q3[2] = 1\n",
    "    return q3\n",
    "\n",
    "def q8ClassToQ2(q8Labels):\n",
    "    \n",
    "    q2 = np.zeros(2)\n",
    "    index = np.argmax(q8Labels)\n",
    "    #Helix\n",
    "    if index == 5: # or index == 3 or index == 4 : # H ,G, I\n",
    "        q2[0] = 1\n",
    "    else:\n",
    "        q2[1] = 1  \n",
    "    return q2\n",
    "\n",
    "def q8toQ8(q8Labels):\n",
    "    return q8Labels\n",
    "\n",
    "def changeQ8Class(dataSet, reductionFunction, numberOfFeatures):\n",
    "\n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    labels_new = np.zeros((num_seqs, seqlen, numberOfFeatures))\n",
    "\n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        for j in range(np.size(dataSet, axis=1)):\n",
    "            oneHot = reductionFunction(dataSet[i, j, 22:30])\n",
    "            features = np.concatenate((dataSet[i, j, 0:21], oneHot), axis=None)\n",
    "            features = np.concatenate((features, dataSet[i, j, 35:56]), axis=None)\n",
    "            labels_new[i][j] = features\n",
    "    return labels_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapClassLabel(features, classLabel, classSize):\n",
    "\n",
    "    res = np.concatenate((features[0:21], classLabel), axis=None)\n",
    "    res = np.concatenate((res, features[ (21+classSize) :]), axis=None)\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#num_classes should be q8, q3 or maybe q2?\n",
    "def proteinSequenceToWindowSequence(windowSize, predictionIndex , dataSet, classSize):\n",
    "   \n",
    "    num_seqs = np.size(dataSet, 0)\n",
    "    seqlen = np.size(dataSet, 1)\n",
    "    features = np.size(dataSet, 2)\n",
    "    dataSet_new = np.zeros((num_seqs, seqlen - windowSize + 1, windowSize, features))\n",
    "    \n",
    "    for i in range(np.size(dataSet, axis=0)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        for j in range(np.size(dataSet, axis=1) - windowSize):\n",
    "            classLabel = dataSet[i][j + predictionIndex][21 : (21+classSize) ]\n",
    "            for k in range(windowSize):\n",
    "                if predictionIndex != 0:\n",
    "                    dataSet_new[i][j][k] = swapClassLabel(dataSet[i][j+k], classLabel, classSize)\n",
    "                else:\n",
    "                    dataSet_new[i][j][k] = swapClassLabel(dataSet[i][j+k+1], classLabel, classSize)\n",
    "            \n",
    "    return dataSet_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWindowsWithPadding(dataSet, windowSize, numberOfFeatures):\n",
    "    \n",
    "    dataSet = np.reshape(dataSet, (dataSet.shape[0]*dataSet.shape[1], windowSize, numberOfFeatures))\n",
    "    dataSet = dataSet[np.count_nonzero( dataSet, axis=(1,2))>(int(windowSize/2)*23), :, :] \n",
    "    \n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_dataset(X_train, X_valid, reductionFunction, numberOfFeatures, classSize, predictionIndex, windowSize):\n",
    "    #print(X_train.shape)\n",
    "    #X_train = changeQ8Class(X_train, reductionFunction, numberOfFeatures)\n",
    "    print(X_train.shape, \"changed train data to class of size \", classSize)\n",
    "    X_train_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_train, classSize)\n",
    "    print(X_train_window.shape, \"changed train data  to window sequence of size \", windowSize)\n",
    "    X_train_window = removeWindowsWithPadding(X_train_window , windowSize, numberOfFeatures)\n",
    "    print(X_train_window.shape, \"filtered windows withouth padding of train data \")\n",
    "\n",
    "    #print(X_valid.shape)\n",
    "    X_valid_window = 0\n",
    "    #X_valid = changeQ8Class(X_valid, reductionFunction, numberOfFeatures)\n",
    "    #print(X_valid.shape, \"changed validation data to class size \", classSize)\n",
    "    #X_valid_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_valid, classSize)\n",
    "    #print(X_valid_window.shape, \"changed validation data to window sequence of size \", windowSize)\n",
    "    #X_valid_window = removeWindowsWithPadding(X_valid_window , windowSize, numberOfFeatures)\n",
    "    #print(X_valid_window.shape, \"filtered windows withouth padding of validation data\")\n",
    "    \n",
    "    return X_train_window, X_valid_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_tapped(oneHot, index, windowSize):\n",
    "\n",
    "    oneHot = oneHot.copy()\n",
    "    newOne = 0.5/(windowSize - 1) * index + 0.5\n",
    "    newZero = (1 - newOne) / (np.size(oneHot) - 1)\n",
    "        \n",
    "    oneHot = oneHot.astype(theano.config.floatX)\n",
    "    oneHot[ oneHot == 1] = newOne\n",
    "    oneHot[ oneHot == 0] = newZero\n",
    "\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tapped_one_dataset(dataSet, windowSize, classSize):\n",
    "    \n",
    "    newDataSet = dataSet.copy()\n",
    "    for i in range(np.size(newDataSet, axis=1)): \n",
    "        for j in range(np.size(newDataSet, axis=1)):\n",
    "\n",
    "            oneHot = one_hot_to_tapped( newDataSet[i, j, 0:21], j, windowSize)\n",
    "            features = np.concatenate((oneHot, newDataSet[i, j, 21:]), axis=None)\n",
    "            newDataSet[i][j] = features\n",
    "    \n",
    "    return newDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(X_train, X_valid, classSize, pssm = False):\n",
    "\n",
    "    if not pssm:\n",
    "        return (X_train[:,:,0:21], X_train[:,:,21 : (21+classSize)], \n",
    "                X_valid[:,:,0:21], X_valid[:,:,21 : (21+classSize)])\n",
    "    else:\n",
    "        return (X_train[:,:,21+classSize:], X_train[:,:,21 : (21+classSize)],\n",
    "                X_valid[:,:,21+classSize:], X_valid[:,:,21 : (21+classSize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 19 #19\n",
    "predictionIndex = 9\n",
    "classSize = 8  # 2 or 3 \n",
    "numberOfFeatures = 50 #50 #44 #45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading casp part dataset\n",
      "(5278, 700, 50)\n",
      "(5278, 700, 50) changed train data to class of size  8\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "(5278, 682, 19, 50) changed train data  to window sequence of size  19\n",
      "(942766, 19, 50) filtered windows withouth padding of train data \n",
      "(942766, 19, 50)\n",
      "saving casp part window dataset\n",
      "reading casp part dataset\n",
      "(5278, 700, 50)\n",
      "(5278, 700, 50) changed train data to class of size  8\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "(5278, 682, 19, 50) changed train data  to window sequence of size  19\n",
      "(928910, 19, 50) filtered windows withouth padding of train data \n",
      "(928910, 19, 50)\n",
      "saving casp part window dataset\n",
      "reading casp part dataset\n",
      "(5278, 700, 50)\n",
      "(5278, 700, 50) changed train data to class of size  8\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "(5278, 682, 19, 50) changed train data  to window sequence of size  19\n",
      "(940480, 19, 50) filtered windows withouth padding of train data \n",
      "(940480, 19, 50)\n",
      "saving casp part window dataset\n",
      "reading casp part dataset\n",
      "(5278, 700, 50)\n",
      "(5278, 700, 50) changed train data to class of size  8\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "(5278, 682, 19, 50) changed train data  to window sequence of size  19\n",
      "(950986, 19, 50) filtered windows withouth padding of train data \n",
      "(950986, 19, 50)\n",
      "saving casp part window dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    print(\"reading casp part dataset\")\n",
    "    f = gzip.GzipFile( 'casp12/training_30-' + str(i) + '.npy.gz',  \"r\")\n",
    "    dataset_part =  np.load(f)\n",
    "    print(dataset_part.shape)\n",
    "    \n",
    "    X_train_window, X_valid_window = get_reshaped_dataset(dataset_part, 0, q8toQ8, numberOfFeatures, classSize, predictionIndex, windowSize)\n",
    "    print(X_train_window.shape)\n",
    "    \n",
    "    del dataset_part\n",
    "    print(\"saving casp part window dataset\")\n",
    "    g = gzip.GzipFile( 'casp12/training_30-' + str(i) + 'window19Middle' +'.npy.gz', \"w\")\n",
    "    np.save(g, X_train_window)\n",
    "    g.close()\n",
    "    del X_train_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_window, X_valid_window = get_reshaped_dataset(X_train, X_valid, q8toQ8, numberOfFeatures, classSize, predictionIndex, windowSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_dataset_window19Middle.npy', X_train_window) # save\n",
    "np.save('X_valid_window19Middle.npy', X_valid_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.GzipFile('all_dataset_window9LeftSideQ2.npy.gz', \"w\")\n",
    "np.save(f, X_train_window)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gzip.GzipFile('X_valid_window19Middle.npy.gz', \"w\")\n",
    "np.save(g, X_valid_window)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = changeQ8Class(X_test, q8ClassToQ2, numberOfFeatures)\n",
    "X_test_window = proteinSequenceToWindowSequence(windowSize,predictionIndex, X_test, classSize)\n",
    "X_test_window = removeWindowsWithPadding(X_test_window , windowSize, numberOfFeatures)\n",
    "print(X_test_window.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.GzipFile('cb513_window19Q2.npy.gz', \"w\")\n",
    "np.save(f, X_test_window)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
